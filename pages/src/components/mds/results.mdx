# Results
## Partially Relevant Video Retrieval (PRVR):
![img](./imgs/prvr.png)
*TABLE: Results of PRVR on ActivityNet Captions and Charades-STA.*

## Video Question Answering:
![img](./imgs/visual.png)
*Figure: Qualitative results of our method and VideoLLaVa. The videos are from ActivityNet Captions.*

![img](./imgs/llm_qa.png)
*TABLE: LLM-Assisted evaluation results of zero-shot video question answering on MSRVTT-QA and ActivityNet-QA. The best performance is denoted by bold numbers.*

![img](./imgs/mc_qa.png)
*TABLE: Multiple-choice QA accuracy on EgoSchema. The best performance is denoted by bold numbers.*

![img](./imgs/next_qa.png)
*TABLE: NExT-QA video question answering results. We report the accuracy for both the supervised and zero-shot methods.*

## Video Retrieval:
![img](./imgs/msrvtt.png)
*TABLE: Results of zero-shot video retrieval on MSRVTT. # V-T Data means the number of video-text paired data used to pre-train or finetune the model. The number I and II represent multimodal-based methods and LLM-based methods, respectively.*

![img](./imgs/anet_cap.png)
*TABLE: Results of zero-shot video retrieval on ActivityNet Captions. #V-T Data means the number of video-text paired data used to pre-train the model.*